{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZctvSuKIP1R"
      },
      "source": [
        "#RANKING THE SENTENCES USING POS-TAGGING and TAKING THE TOP RANKED SENTENCES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeTg-e6yD_Ie",
        "outputId": "2f35cf91-56b3-4be5-d792-3e0861b611b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtqehKMuENTM"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from collections import defaultdict\n",
        "text = \"\"\"\n",
        "The quick brown fox jumped over the lazy dog. The dog barked loudly. The fox was startled and ran away. \n",
        "The cat watched from the tree. The sky turned dark and it started to rain heavily.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx3fjl1IFjRY",
        "outputId": "df8cc6eb-302b-4f9b-c67c-6c5122eab830"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[('The', 'DT'),\n",
              "  ('quick', 'JJ'),\n",
              "  ('brown', 'NN'),\n",
              "  ('fox', 'NN'),\n",
              "  ('jumped', 'VBD'),\n",
              "  ('over', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('lazy', 'JJ'),\n",
              "  ('dog', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('The', 'DT'),\n",
              "  ('dog', 'NN'),\n",
              "  ('barked', 'VBD'),\n",
              "  ('loudly', 'RB'),\n",
              "  ('.', '.')],\n",
              " [('The', 'DT'),\n",
              "  ('fox', 'NN'),\n",
              "  ('was', 'VBD'),\n",
              "  ('startled', 'VBN'),\n",
              "  ('and', 'CC'),\n",
              "  ('ran', 'VBD'),\n",
              "  ('away', 'RB'),\n",
              "  ('.', '.')],\n",
              " [('The', 'DT'),\n",
              "  ('cat', 'NN'),\n",
              "  ('watched', 'VBD'),\n",
              "  ('from', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('tree', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('The', 'DT'),\n",
              "  ('sky', 'NN'),\n",
              "  ('turned', 'VBD'),\n",
              "  ('dark', 'JJ'),\n",
              "  ('and', 'CC'),\n",
              "  ('it', 'PRP'),\n",
              "  ('started', 'VBD'),\n",
              "  ('to', 'TO'),\n",
              "  ('rain', 'VB'),\n",
              "  ('heavily', 'RB'),\n",
              "  ('.', '.')]]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences = sent_tokenize(text)\n",
        "tagged_sentences = [pos_tag(word_tokenize(sent)) for sent in sentences]\n",
        "tagged_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6q8wy77GF3h",
        "outputId": "d2c9f3d9-2b9b-4024-d320-d4117c397ddb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(int, {})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "  sentence_scores = defaultdict(int)\n",
        "  sentence_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4fImgk-Gv2m"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "important_pos_tags = [\"NN\", \"NNS\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", \"JJ\", \"JJR\", \"JJS\"]\n",
        "for i in range(len(tagged_sentences)):\n",
        "        for word, pos_tag in tagged_sentences[i]:\n",
        "            if pos_tag in important_pos_tags and word.lower() not in stop_words:\n",
        "                sentence_scores[i] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF5BdaenG6RF",
        "outputId": "0a57457a-e635-4cea-e02f-1b69b721dd8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(int, {0: 6, 1: 2, 2: 3, 3: 3, 4: 5})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phn_L6HVGzBi",
        "outputId": "402a97d8-e892-4e61-e99f-0fa0bea46620"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 4, 2, 3, 1]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)\n",
        "sorted_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgvSE5BWG_Lh"
      },
      "outputs": [],
      "source": [
        "candidate_sentences = sorted_sentences[:3]\n",
        "sentence_scores\n",
        "summary = \" \".join([sentences[i] for i in sorted(candidate_sentences)])\n",
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLcgkuS2Ime6"
      },
      "source": [
        "MAKING FUNCTION FOR POS TAGGING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91oND6eKH7ij",
        "outputId": "8f5dd4bd-f841-46c2-b3cd-6e41b2332add"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary:\n",
            "\n",
            "The quick brown fox jumped over the lazy dog. The fox was startled and ran away. The sky turned dark and it started to rain heavily.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import math\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load the NLTK stop words\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Example usage\n",
        "text = \"\"\"\n",
        "The quick brown fox jumped over the lazy dog. The dog barked loudly. The fox was startled and ran away. \n",
        "The cat watched from the tree. The sky turned dark and it started to rain heavily.\n",
        "\"\"\"\n",
        "\n",
        "def pos_tagging_summarization(text, num_sentences=math.ceil(len(sent_tokenize(text))*.5)):\n",
        "    # Tokenize the text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "    \n",
        "    # Tokenize the sentences into words and perform POS tagging\n",
        "    tagged_sentences = [pos_tag(word_tokenize(sent)) for sent in sentences]\n",
        "    \n",
        "    # Create a dictionary to store the sentence scores\n",
        "    sentence_scores = defaultdict(int)\n",
        "    \n",
        "    # Define the POS tags that are considered important\n",
        "    important_pos_tags = [\"NN\", \"NNS\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", \"JJ\", \"JJR\", \"JJS\"]\n",
        "    \n",
        "    # Loop through each tagged sentence and calculate sentence scores based on the occurrence of important POS tags\n",
        "    for i in range(len(tagged_sentences)):\n",
        "        for word, p_t in tagged_sentences[i]:\n",
        "            if p_t in important_pos_tags and word.lower() not in stop_words:\n",
        "                sentence_scores[i] += 1\n",
        "    \n",
        "    # Sort the sentences based on their scores in descending order\n",
        "    sorted_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)\n",
        "    \n",
        "    # Select the top 'num_sentences' sentences as candidate summary sentences\n",
        "    candidate_sentences = sorted_sentences[:num_sentences]\n",
        "    \n",
        "    # Sort the candidate sentences based on their occurrence in the original text\n",
        "    summary = \" \".join([sentences[i] for i in sorted(candidate_sentences)])\n",
        "    \n",
        "    return summary\n",
        "\n",
        "\n",
        "summary = pos_tagging_summarization(text)\n",
        "print(\"Summary:\")\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UcOJAGLJa3e"
      },
      "source": [
        "#GENERATING DATA USING MARKOV MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLtJ_ZU9JVlq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7fbK66VKcpv",
        "outputId": "ae65a7c0-ccf6-4215-af34-c7183e77c2a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of words =  36\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"\n",
        "The quick brown fox jumped over the lazy dog. The dog barked loudly. The fox was startled and ran away. \n",
        "The cat watched from the tree. The sky turned dark and it started to rain heavily.\n",
        "\"\"\"\n",
        "def clean_txt(txt):\n",
        "    cleaned_txt = []\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    for line in sentences:\n",
        "        line = line.lower()\n",
        "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n",
        "        tokens = word_tokenize(line)\n",
        "        words = [word for word in tokens if word.isalpha()]\n",
        "        cleaned_txt+=words\n",
        "    return cleaned_txt\n",
        "\n",
        "cleaned_text = clean_txt(text)\n",
        "print(\"number of words = \", len(cleaned_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etqVPUgPQztI",
        "outputId": "6fa1f8b8-0e96-4f2c-dc8b-0900cd42add1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the',\n",
              " 'quick',\n",
              " 'brown',\n",
              " 'fox',\n",
              " 'jumped',\n",
              " 'over',\n",
              " 'the',\n",
              " 'lazy',\n",
              " 'dog',\n",
              " 'the',\n",
              " 'dog',\n",
              " 'barked',\n",
              " 'loudly',\n",
              " 'the',\n",
              " 'fox',\n",
              " 'was',\n",
              " 'startled',\n",
              " 'and',\n",
              " 'ran',\n",
              " 'away',\n",
              " 'the',\n",
              " 'cat',\n",
              " 'watched',\n",
              " 'from',\n",
              " 'the',\n",
              " 'tree',\n",
              " 'the',\n",
              " 'sky',\n",
              " 'turned',\n",
              " 'dark',\n",
              " 'and',\n",
              " 'it',\n",
              " 'started',\n",
              " 'to',\n",
              " 'rain',\n",
              " 'heavily']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Jd1UhEvzs2",
        "outputId": "b5cc0155-9b6a-4a4f-8836-b58089802927"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 'DT'),\n",
              " ('quick', 'JJ'),\n",
              " ('brown', 'NN'),\n",
              " ('fox', 'NN'),\n",
              " ('jumped', 'VBD'),\n",
              " ('over', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('lazy', 'JJ'),\n",
              " ('dog', 'NN'),\n",
              " ('the', 'DT'),\n",
              " ('dog', 'NN'),\n",
              " ('barked', 'VBD'),\n",
              " ('loudly', 'RB'),\n",
              " ('the', 'DT'),\n",
              " ('fox', 'NN'),\n",
              " ('was', 'VBD'),\n",
              " ('startled', 'VBN'),\n",
              " ('and', 'CC'),\n",
              " ('ran', 'VB'),\n",
              " ('away', 'RB'),\n",
              " ('the', 'DT'),\n",
              " ('cat', 'NN'),\n",
              " ('watched', 'VBD'),\n",
              " ('from', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('tree', 'NN'),\n",
              " ('the', 'DT'),\n",
              " ('sky', 'NN'),\n",
              " ('turned', 'VBD'),\n",
              " ('dark', 'JJ'),\n",
              " ('and', 'CC'),\n",
              " ('it', 'PRP'),\n",
              " ('started', 'VBD'),\n",
              " ('to', 'TO'),\n",
              " ('rain', 'VB'),\n",
              " ('heavily', 'RB')]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tags = pos_tag(cleaned_text)\n",
        "tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiJ1xV-7w_w1",
        "outputId": "6c403e8f-f020-4bd7-b367-39c9fd5b74d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "tagged_cleaned_text = []\n",
        "important_pos_tags = [\"NN\", \"NNS\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", \"JJ\", \"JJR\", \"JJS\"]\n",
        "for i in tags:\n",
        "  if i[1] in important_pos_tags:\n",
        "    tagged_cleaned_text.append(i[0])\n",
        "len(tagged_cleaned_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PEPmavnNYni"
      },
      "outputs": [],
      "source": [
        "def make_markov_model(cleaned_stories, n_gram=2):    #to get contextual info we are using n_gram\n",
        "    markov_model = {}\n",
        "    for i in range(len(cleaned_stories)-n_gram-1):\n",
        "        curr_state, next_state = \"\", \"\"\n",
        "        for j in range(n_gram):\n",
        "            curr_state += cleaned_stories[i+j] + \" \"\n",
        "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
        "        curr_state = curr_state[:-1]\n",
        "        next_state = next_state[:-1]\n",
        "        \n",
        "        if curr_state not in markov_model:\n",
        "            markov_model[curr_state] = {}\n",
        "            markov_model[curr_state][next_state] = 1\n",
        "        else:\n",
        "            if next_state in markov_model[curr_state]:\n",
        "                markov_model[curr_state][next_state] += 1\n",
        "            else:\n",
        "                markov_model[curr_state][next_state] = 1\n",
        "    # calculating transition probabilities\n",
        "    for curr_state, transition in markov_model.items():\n",
        "        total = sum(transition.values())\n",
        "        for state, count in transition.items():\n",
        "            markov_model[curr_state][state] = count/total\n",
        "    return markov_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5vjLIHTQT1v",
        "outputId": "46a63a6b-c9fb-4bda-b00f-819556ff02b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'quick brown': {'fox jumped': 1.0},\n",
              " 'brown fox': {'jumped lazy': 1.0},\n",
              " 'fox jumped': {'lazy dog': 1.0},\n",
              " 'jumped lazy': {'dog dog': 1.0},\n",
              " 'lazy dog': {'dog barked': 1.0},\n",
              " 'dog dog': {'barked fox': 1.0},\n",
              " 'dog barked': {'fox was': 1.0},\n",
              " 'barked fox': {'was startled': 1.0},\n",
              " 'fox was': {'startled ran': 1.0},\n",
              " 'was startled': {'ran cat': 1.0},\n",
              " 'startled ran': {'cat watched': 1.0},\n",
              " 'ran cat': {'watched tree': 1.0},\n",
              " 'cat watched': {'tree sky': 1.0},\n",
              " 'watched tree': {'sky turned': 1.0},\n",
              " 'tree sky': {'turned dark': 1.0},\n",
              " 'sky turned': {'dark started': 1.0},\n",
              " 'turned dark': {'started rain': 1.0}}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "markov_model = make_markov_model(tagged_cleaned_text,2)\n",
        "markov_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAXMSbY7QatM",
        "outputId": "b0198d42-f95b-4465-f5fa-6e546a848b60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of states =  17\n"
          ]
        }
      ],
      "source": [
        "print(\"number of states = \", len(markov_model.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjfRZJ-CkURx"
      },
      "outputs": [],
      "source": [
        "def generate_story(markov_model, limit=10, start=''):\n",
        "    n = 0\n",
        "    curr_state = start\n",
        "    next_state = None\n",
        "    story = \"\"\n",
        "    story+=curr_state+\" \"\n",
        "    while n<limit:\n",
        "      try:\n",
        "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
        "                                    list(markov_model[curr_state].values()))\n",
        "        curr_state = next_state[0]\n",
        "        story+=curr_state+\" \"\n",
        "        n+=1\n",
        "      except KeyError:\n",
        "        return story\n",
        "    return story"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT79LKRTqfRB",
        "outputId": "3d0028b3-51f2-4ac9-ba0d-83e979f2c558"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['quick brown',\n",
              " 'brown fox',\n",
              " 'fox jumped',\n",
              " 'jumped lazy',\n",
              " 'lazy dog',\n",
              " 'dog dog',\n",
              " 'dog barked',\n",
              " 'barked fox',\n",
              " 'fox was',\n",
              " 'was startled',\n",
              " 'startled ran',\n",
              " 'ran cat',\n",
              " 'cat watched',\n",
              " 'watched tree',\n",
              " 'tree sky',\n",
              " 'sky turned',\n",
              " 'turned dark']"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(markov_model.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GdCQ8zmoKP0",
        "outputId": "6a7a9ab1-3983-4914-e814-c2172c948147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dog barked\n",
            "dog dog\n",
            "turned dark\n",
            "fox was\n",
            "ran cat\n"
          ]
        }
      ],
      "source": [
        "stories = []\n",
        "for i in range(5):\n",
        "  import random\n",
        "\n",
        "\n",
        "  # Get a random key from the dictionary\n",
        "  random_key = random.choice(list(markov_model.keys()))\n",
        "  print(random_key)\n",
        "  story = generate_story(markov_model,10,start=str(random_key))\n",
        "  stories.append(story)\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDnNyPyAoSok",
        "outputId": "c9f47664-eb85-489b-9ce3-7ceda10fadab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the lazy dog the dog barked loudly the fox was startled and ran away the cat watched from the tree the sky ',\n",
              " 'barked loudly the fox was startled and ran away the cat watched from the tree the sky turned dark and it started ',\n",
              " 'it started to rain ',\n",
              " 'dog barked loudly the fox was startled and ran away the cat watched from the tree the sky turned dark and it ',\n",
              " 'dark and it started to rain ']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-H5F-hQprWX",
        "outputId": "bfa9e4da-9f38-4ffe-be96-d5f4c17f98dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['barked the fox was startled ran the cat watched the tree the sky turned dark started ',\n",
              " 'brown fox jumped the lazy dog the dog barked the fox was startled ran the cat watched the tree the sky turned ',\n",
              " 'ran the cat watched the tree the sky turned dark started rain ',\n",
              " 'the dog barked the fox was startled ran the cat watched the tree the sky turned dark started ',\n",
              " 'startled ran the cat watched the tree the sky turned dark started ']"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF6apO0-3T-M"
      },
      "source": [
        "**USING TEXT RANK ON STORIES To Generate Summary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c5v7TW75Q6N",
        "outputId": "87ee43b4-e16d-4f57-aaa5-db107dc968ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from string import punctuation\n",
        "from collections import defaultdict\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puSESpet4L7v",
        "outputId": "8b61bdc7-172d-4086-b63f-505520044a81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-13 23:08:39--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-04-13 23:08:40--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-04-13 23:08:40--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2023-04-13 23:11:20 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GZGM9QS4QMJ",
        "outputId": "39a538f5-c5cf-4063-c006-d57f1b16b407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "!unzip glove*.zip\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rmaX8Mf4Z3O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#Extract word vectors\n",
        "word_embeddings = {}\n",
        "f = open('glove.6B.100d.txt',encoding = 'utf-8')\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:],dtype = 'float32')\n",
        "  word_embeddings[word] = coefs\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUpWqBi84qJc",
        "outputId": "de35ea0d-75c2-4426-a40e-85f495d5e469"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english') + list(punctuation))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess(sentence):\n",
        "    words = word_tokenize(sentence.lower())\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return words\n",
        "\n",
        "processed_sentences = [preprocess(sentence) for sentence in stories]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC7u9p7T5r5o",
        "outputId": "a6187f77-b142-41c7-f191-d53866d5593e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['dog',\n",
              "  'barked',\n",
              "  'fox',\n",
              "  'startled',\n",
              "  'ran',\n",
              "  'cat',\n",
              "  'watched',\n",
              "  'tree',\n",
              "  'sky',\n",
              "  'turned',\n",
              "  'dark',\n",
              "  'started',\n",
              "  'rain'],\n",
              " ['dog',\n",
              "  'dog',\n",
              "  'barked',\n",
              "  'fox',\n",
              "  'startled',\n",
              "  'ran',\n",
              "  'cat',\n",
              "  'watched',\n",
              "  'tree',\n",
              "  'sky',\n",
              "  'turned',\n",
              "  'dark',\n",
              "  'started'],\n",
              " ['turned', 'dark', 'started', 'rain'],\n",
              " ['fox',\n",
              "  'startled',\n",
              "  'ran',\n",
              "  'cat',\n",
              "  'watched',\n",
              "  'tree',\n",
              "  'sky',\n",
              "  'turned',\n",
              "  'dark',\n",
              "  'started',\n",
              "  'rain'],\n",
              " ['ran', 'cat', 'watched', 'tree', 'sky', 'turned', 'dark', 'started']]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voYFyyss5zUi"
      },
      "outputs": [],
      "source": [
        "#vectorize sentences\n",
        "sentence_vectors = []\n",
        "for i in processed_sentences:\n",
        "  if len(i) != 0:\n",
        "    v = sum([word_embeddings.get(w,np.zeros((100,))) for w in i])/(len(i)+0.001)\n",
        "  else:\n",
        "    v = np.zeros((100,))\n",
        "  sentence_vectors.append(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nNEsPqy6Bju",
        "outputId": "47ceb72d-7e0e-413d-9e67-9c1eadc2d01f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sentence_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_AjEnE96Hlq"
      },
      "outputs": [],
      "source": [
        "# similarity matrix\n",
        "sim_mat = np.zeros([len(stories),len(stories)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqReLpWX6LMU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "     \n",
        "\n",
        "for i in range(len(stories)):\n",
        "  for j in range(len(stories)):\n",
        "    if i!=j:\n",
        "      sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100),sentence_vectors[j].reshape(1,100))[0,0]\n",
        "\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KJ5w-L-B6q3n"
      },
      "outputs": [],
      "source": [
        "!pip install scipy==1.8.0 \n",
        "!pip install networkx==2.6\n",
        "     \n",
        "\n",
        "#Creating a graph\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "UGu0g89O6v49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8452d58f-d569-4cb3-fdce-9bd722c25ab3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.20389041334474767,\n",
              " 1: 0.19841510140931687,\n",
              " 2: 0.18971445367920742,\n",
              " 3: 0.2048167168073209,\n",
              " 4: 0.20316331475940697}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "nx_graph = nx.from_numpy_array(sim_mat)\n",
        "scores = nx.pagerank(nx_graph)\n",
        "scores\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(stories)),reverse=True)\n",
        "     \n",
        "\n",
        "ranked_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgUoLan47ZJS",
        "outputId": "b946b1a6-ce7f-4f95-dce8-9305ad608515"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.2048167168073209,\n",
              "  'fox was startled ran cat watched tree sky turned dark started rain '),\n",
              " (0.20389041334474767,\n",
              "  'dog barked fox was startled ran cat watched tree sky turned dark started rain '),\n",
              " (0.20316331475940697, 'ran cat watched tree sky turned dark started '),\n",
              " (0.19841510140931687,\n",
              "  'dog dog barked fox was startled ran cat watched tree sky turned dark started '),\n",
              " (0.18971445367920742, 'turned dark started rain ')]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "s=\"\"\n",
        "for i in range(math.ceil(len(stories)*(.5))):\n",
        "  s=s+ranked_sentences[i][1]"
      ],
      "metadata": {
        "id": "3tifac267jBj"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lu-vTx779l9",
        "outputId": "f99323b7-0cee-49d6-e48d-1fcc5ca57fac"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fox was startled ran cat watched tree sky turned dark started rain dog barked fox was startled ran cat watched tree sky turned dark started rain ran cat watched tree sky turned dark started \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_CctnCHS8Tbp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}